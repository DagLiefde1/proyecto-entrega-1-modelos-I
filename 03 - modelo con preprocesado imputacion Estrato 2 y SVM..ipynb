{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d38235d",
   "metadata": {},
   "source": [
    "# Librerías\n",
    "Importación de todas las librerías necesarias para manipulación de datos, escalado, modelado, validación y evaluación. Se hace uso de pandas, numpy y módulos de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd7d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc9ea8",
   "metadata": {},
   "source": [
    "### Preparación y Limpieza de los Datos Socioeconómicos\n",
    "\n",
    "Esta etapa se enfoca en preparar los datos que alimentarán el modelo de aprendizaje automático, garantizando su calidad y formato adecuados. A continuación, se describen los pasos clave:\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Cargar Datos\n",
    "\n",
    "Se importan los archivos `train.csv` y `test.csv`, los cuales contienen información sobre los estudiantes.\n",
    "\n",
    "* El conjunto `train` incluye la variable objetivo `RENDIMIENTO_GLOBAL`.\n",
    "* El conjunto `test` será utilizado posteriormente para realizar predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Selección de Columnas Socioeconómicas Relevantes\n",
    "\n",
    "Se seleccionan cuatro variables clave relacionadas con el entorno familiar del estudiante:\n",
    "\n",
    "* `FAMI_ESTRATOVIVIENDA`: Estrato socioeconómico del hogar.\n",
    "* `FAMI_TIENEINTERNET`: Acceso a internet en el hogar.\n",
    "* `FAMI_EDUCACIONPADRE` y `FAMI_EDUCACIONMADRE`: Nivel educativo de los padres.\n",
    "\n",
    "Estas columnas, junto con el `ID` y la variable objetivo (`RENDIMIENTO_GLOBAL`), se conservan en los conjuntos de datos.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Limpieza de Valores Atípicos o Raros\n",
    "\n",
    "En los datos pueden aparecer valores codificados como `98`, `99`, o `999` que representan respuestas inválidas, desconocidas o no aplicables.\n",
    "Estos valores se reemplazan por `NaN` (valores faltantes) para tratarlos adecuadamente en el siguiente paso.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Imputación de Valores Faltantes\n",
    "\n",
    "Se realiza una **imputación simple por moda**:\n",
    "\n",
    "* Para cada columna, se calcula el valor más frecuente (moda).\n",
    "* Ese valor se utiliza para rellenar los campos faltantes, tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "Este enfoque es útil cuando se trabaja con variables categóricas y se desea mantener la consistencia.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Codificación One-Hot\n",
    "\n",
    "Las variables categóricas no pueden ser procesadas directamente por la mayoría de los modelos.\n",
    "Por eso, se aplica **One-Hot Encoding**, que convierte cada categoría en una nueva columna binaria (0 o 1).\n",
    "\n",
    "Esta técnica evita supuestos de orden o magnitud entre categorías y prepara los datos para el modelo SVM, que es sensible a la representación de las variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f013a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "cols = [\n",
    "    'FAMI_ESTRATOVIVIENDA',\n",
    "    'FAMI_TIENEINTERNET',\n",
    "    'FAMI_EDUCACIONPADRE',\n",
    "    'FAMI_EDUCACIONMADRE'\n",
    "]\n",
    "train = train[['ID'] + cols + ['RENDIMIENTO_GLOBAL']]\n",
    "test = test[['ID'] + cols]\n",
    "\n",
    "valores_raros = ['98', '99', '999', 98, 99, 999]\n",
    "for col in cols:\n",
    "    train[col] = train[col].replace(valores_raros, np.nan)\n",
    "    test[col] = test[col].replace(valores_raros, np.nan)\n",
    "\n",
    "for col in cols:\n",
    "    modo = train[col].mode()[0]\n",
    "    train[col] = train[col].fillna(modo)\n",
    "    test[col] = test[col].fillna(modo)\n",
    "\n",
    "def one_hot(df, col):\n",
    "    return pd.concat([df.drop(columns=[col]), pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "\n",
    "for col in cols:\n",
    "    train = one_hot(train, col)\n",
    "    test = one_hot(test, col)\n",
    "\n",
    "test = test.reindex(columns=train.drop(columns=['RENDIMIENTO_GLOBAL']).columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ba663",
   "metadata": {},
   "source": [
    "### Modelado, Evaluación y Predicción\n",
    "\n",
    "En esta etapa se realiza la transformación de la variable objetivo, el entrenamiento del modelo SVM (Support Vector Machine), su validación, y finalmente se generan las predicciones para el conjunto de prueba.\n",
    "\n",
    "---\n",
    "\n",
    "#### Codificación de la Variable Objetivo\n",
    "\n",
    "La variable `RENDIMIENTO_GLOBAL` es de tipo categórico con niveles: `bajo`, `medio-bajo`, `medio-alto` y `alto`.\n",
    "\n",
    "* Se convierte a valores numéricos con un mapeo ordinal:\n",
    "\n",
    "  * `bajo → 0`\n",
    "  * `medio-bajo → 1`\n",
    "  * `medio-alto → 2`\n",
    "  * `alto → 3`\n",
    "\n",
    "Esto facilita el uso del modelo SVM, que requiere variables numéricas.\n",
    "\n",
    "---\n",
    "\n",
    "#### Escalado de los Datos\n",
    "\n",
    "Se normalizan las variables predictoras (`X`) usando **`StandardScaler`**.\n",
    "Esto es esencial en SVM porque la escala de las variables puede afectar significativamente el rendimiento del modelo.\n",
    "\n",
    "* `fit_transform` se aplica al conjunto de entrenamiento.\n",
    "* `transform` se aplica al conjunto de prueba para mantener la coherencia.\n",
    "\n",
    "---\n",
    "\n",
    "#### División para Validación\n",
    "\n",
    "Para evaluar el modelo antes de hacer predicciones finales, se divide el conjunto de entrenamiento en dos partes:\n",
    "\n",
    "* 70% para entrenamiento (`Xtrain`, `ytrain`)\n",
    "* 30% para validación (`Xval`, `yval`)\n",
    "\n",
    "Esto permite probar el modelo en datos no vistos antes de hacer predicciones definitivas.\n",
    "\n",
    "---\n",
    "\n",
    "#### Entrenamiento del Modelo\n",
    "\n",
    "Se entrena un modelo **SVM con kernel RBF** (`radial basis function`), que permite capturar relaciones no lineales en los datos.\n",
    "\n",
    "Parámetros usados:\n",
    "\n",
    "* `C=1`: penaliza errores de clasificación (trade-off bias/varianza).\n",
    "* `gamma='scale'`: ajuste automático del parámetro del kernel.\n",
    "\n",
    "---\n",
    "\n",
    "#### Evaluación del Modelo\n",
    "\n",
    "Se evalúa el rendimiento del modelo con:\n",
    "\n",
    "* **Accuracy en el conjunto de validación** (`Xval` vs. `yval`).\n",
    "* **Validación cruzada con 5 particiones (CV=5)** para estimar la generalización del modelo.\n",
    "  Se imprime la media y desviación estándar del accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "#### Predicción Final\n",
    "\n",
    "Una vez validado el modelo, se reentrena con todo el conjunto de entrenamiento (`X_scaled`, `y`) para aprovechar toda la información disponible.\n",
    "\n",
    "Se generan predicciones sobre el conjunto de prueba (`test_scaled`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Generación de Archivo de Envío (`submission.csv`)\n",
    "\n",
    "Se crea un archivo con las predicciones finales.\n",
    "\n",
    "* Se revierte la codificación numérica a categorías originales (`0 → bajo`, etc.).\n",
    "* Se guarda el archivo `submission.csv` con dos columnas: `ID` y `RENDIMIENTO_GLOBAL`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
    "inv_mapa = {v: k for k, v in mapa.items()}\n",
    "y = train['RENDIMIENTO_GLOBAL'].map(mapa)\n",
    "X = train.drop(columns=['RENDIMIENTO_GLOBAL'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "yval_pred = clf.predict(Xval)\n",
    "acc = accuracy_score(yval, yval_pred)\n",
    "print(f\"Accuracy en validación: {acc:.4f}\")\n",
    "scores = cross_val_score(clf, X_scaled, y, cv=5)\n",
    "print(f\"CV Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "clf.fit(X_scaled, y)\n",
    "y_test_pred = clf.predict(test_scaled)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    'RENDIMIENTO_GLOBAL': pd.Series(y_test_pred).map(inv_mapa)\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
